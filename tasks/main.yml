---
  - name: Create RHV Auth token
    ovirt_auth:
      url: "{{ rhv_url }}"
      username: "{{ rhv_username }}"
      password: "{{ rhv_password }}"
      ca_file: "{{ rhv_ca }}"
    no_log: true

  - name: Start VM for testing
    ovirt_vms:
      state: running
      name: "{{ inventory_hostname }}"
      cluster: "{{ rhv_cluster }}"
      auth:
        username: "{{ rhv_username }}"
        password: "{{ rhv_password }}"
        url: "{{ rhv_url }}"
        insecure: true
    delegate_to: localhost

  - name: Put Foreman SELinux into permissive
    selinux:
      policy: targeted
      state: permissive

  - name: Grab bootdisk hammer-cli-foreman patch
    get_url:
      dest: /root/hammer.patch
      url: https://github.com/chris1984/hammer-cli-foreman/commit/a5734584598433f4d7071abc1b2b9fc871a2698b.patch

  - name: Apply patch to hammer-cli-foreman
    patch:
      src: /root/hammer.patch
      remote_src: yes
      dest: /opt/theforeman/tfm/root/usr/share/gems/gems/{{ hammer_version }}/lib/hammer_cli_foreman/hosts/common_update_options.rb
      strip: 1

  - name: Downloading fog-vsphere patch for testing
    get_url:
      dest: /root/fog.patch
      url: "{{ fogpatch_url }}"
    when: test_pr

  - name: Appling /root/fog.patch to fog-vsphere for testing
    patch:
      src: /root/fog.patch
      remote_src: yes
      strip: 1
      basedir: /opt/theforeman/tfm/root/usr/share/gems/gems/{{ fog_version }}/
    when: test_pr

  - name: Download requested version of fog-vsphere
    get_url:
      dest: /root/v{{ test_fog_version }}.tar.gz
      url: https://github.com/fog/fog-vsphere/archive/v{{ test_fog_version }}.tar.gz
      force: yes
    when: override_fog

  - name: Extract fog-vsphere archive into gem directory
    unarchive:
      src: /root/v{{ test_fog_version }}.tar.gz
      dest: /opt/theforeman/tfm/root/usr/share/gems/gems/{{ fog_version }}
      extra_opts:
        - --overwrite
    when: override_fog

  - name: Create fog-testing directory in root
    file:
      path: /root/fog-testing
      state: directory
      mode: 0755

  - name: Restart Katello/Foreman services
    command: foreman-maintain service restart
    args:
      chdir: /root
      creates: /root/fog-testing/restart_services
    no_log: True
    changed_when: True

  - name: Wait 60 seconds for services to be fully up
    wait_for: timeout=60
    delegate_to: localhost

  - name: Upgrade Katello/Foreman to latest
    yum:
       name: '*'
       state: latest
       update_cache: yes
    when: update_satellite

  - name: Run upgrade hook since Katello/Foreman has been upgraded
    command: foreman-installer --upgrade -v -s --disable-system-checks
    args:
      chdir: /root
      creates: /root/fog-testing/upgrade
    when: update_satellite
    register: installer_run

  - name: Generate new API cache data
    command: foreman-rake apipie:cache:index
    args:
      chdir: /root
      creates: /root/fog-testing/apicache_regen
    no_log: True
    changed_when: True

  - name: Check and make sure services are up
    command: hammer ping
    args:
      chdir: /root
      creates: /root/fog-testing/ping_check
    register: hping
    failed_when: hping.rc == 1

  - name: PXE | Normal VM creation with single HDD on Local Datastore
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test1 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1
    args:
      chdir: /root
      creates: /root/fog-testing/test1

  - name: PXE | Normal VM creation with added HDD on Local Datastore
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test2 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --volume name=harddisk1,datastore=Local-Ironforge,size_gb=10,thin=true,eager_zero=false,mode=persistent --volume name=harddisk2,datastore=Local-Ironforge,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test2

  - name: Sleep for {{ vm_timeout }} seconds while 2 VM builds complete
    wait_for: timeout={{ vm_timeout }}
    delegate_to: localhost

  - name: PXE | Normal VM creation with single HDD on Storage Pod
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test3 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test3

  - name: PXE | Normal VM creation with added HDD on Storage Pod
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test4 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent --volume name=harddisk2,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test4

  - name: Sleep for {{ vm_timeout }} seconds while 2 VM builds complete
    wait_for: timeout={{ vm_timeout }}
    delegate_to: localhost

  - name: Bootdisk | Normal VM creation with single HDD on Local Datastore
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test5 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --provision-method bootdisk --medium-id {{ medium_id }} --partition-table-id {{ ptable_id }}
    args:
      chdir: /root
      creates: /root/fog-testing/test5

  - name: Bootdisk | Normal VM creation with added HDD on Local Datastore
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test6 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --provision-method bootdisk --medium-id {{ medium_id }} --partition-table-id {{ ptable_id }} --volume name=harddisk1,datastore=Local-Ironforge,size_gb=10,thin=true,eager_zero=false,mode=persistent --volume name=harddisk2,datastore=Local-Ironforge,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test6

  - name: Sleep for {{ vm_timeout }} seconds while 2 VM builds complete
    wait_for: timeout={{ vm_timeout }}
    delegate_to: localhost

  - name: Bootdisk | Normal VM creation with single HDD on Storage Pod
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test7 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --provision-method bootdisk --medium-id {{ medium_id }} --partition-table-id {{ ptable_id }} --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test7

  - name: Bootdisk | Normal VM creation with added HDD on Storage Pod
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test8 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=1 --provision-method bootdisk --medium-id {{ medium_id }} --partition-table-id {{ ptable_id }} --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent --volume name=harddisk2,datastore=Local-Ironforge,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test8

  - name: Sleep for {{ vm_timeout }} seconds while 2 VM builds complete
    wait_for: timeout={{ vm_timeout }}
    delegate_to: localhost

  - name: Network | Normal VM creation with NIC in portgroup on Distributed Switch with VLAN
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test9 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=0,cluster=SysMgmt_vMotion,resource_pool=Resources --interface compute_type=VirtualVmxnet3,compute_network=VLAN-Test --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test9

  - name: Sleep for 10 seconds while VM build completes
    wait_for: timeout=10
    delegate_to: localhost

  - name: Network | Normal VM creation with NIC in portgroup on Distributed Switch
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test10 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=0,cluster=SysMgmt_vMotion,resource_pool=Resources --interface compute_type=VirtualVmxnet3,compute_network=CEE_VM_Network --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test10

  - name: Sleep for 10 seconds while VM build completes
    wait_for: timeout=10
    delegate_to: localhost

  - name: Network | Normal VM creation with additional NIC
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host create --name test11 --hostgroup-id {{ hostgroup_id }} --location-id {{ location_id }} --organization-id {{ org_id }} --compute-resource-id {{ cr_id }} --compute-profile-id {{ cp_id }} --compute-attributes start=0,cluster=SysMgmt_vMotion,resource_pool=Resources --interface compute_type=VirtualVmxnet3,compute_network=CEE_VM_Network,primary=true --interface compute_type=VirtualVmxnet3,compute_network=VLAN-Test,primary=false --volume name=harddisk1,storage_pod=Synology-Cluster,size_gb=10,thin=true,eager_zero=false,mode=persistent
    args:
      chdir: /root
      creates: /root/fog-testing/test11

  - name: Delete VMS before reverting snapshot to prevent name taken error
    command: hammer -u {{ hammer_user }} -p {{ hammer_password }} host delete --name "{{ item }}"
    args:
      chdir: /root
      creates: /root/fog-testing/remove_vms
    with_items:
      - test1.{{ sat_domain }}
      - test2.{{ sat_domain }}
      - test3.{{ sat_domain }}
      - test4.{{ sat_domain }}
      - test5.{{ sat_domain }}
      - test6.{{ sat_domain }}
      - test7.{{ sat_domain }}
      - test8.{{ sat_domain }}
      - test9.{{ sat_domain }}
      - test10.{{ sat_domain }}
      - test11.{{ sat_domain }}

  - name: Revert VM back to "Ready" snapshot
    ovirt_snapshots:
      vm_name: "{{ inventory_hostname }}"
      state: revert
      snapshot_id: "{{ rhv_snapshotid }}"
    delegate_to: localhost
    when: revert_vm

  - name: Stop VM after snapshot restore
    ovirt_vms:
      state: stopped
      name: "{{ inventory_hostname }}"
      cluster: "{{ rhv_cluster }}"
      auth:
        username: "{{ rhv_username }}"
        password: "{{ rhv_password }}"
        url: "{{ rhv_url }}"
        insecure: true
    delegate_to: localhost
